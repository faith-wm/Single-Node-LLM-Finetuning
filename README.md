# single-node-llm-full-finetuning

Full parameter fine-tuning of LLM (e.g., Llama 3.1) on a single node using deepspeed.

For single-node multi-GPU setting run as --> deepspeed train.py
